{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Recognized Entities:\n",
      "Token: Aoqin Dragon, Label: B-Organization\n",
      "\n",
      "Custom Model Recognized Entities:\n",
      "Token: Aoqin, Label: B-Organization\n",
      "Token: Dragon, Label: PERSON\n",
      "Token: used, Label: B-Organization\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "\n",
    "# Load spaCy's larger model for better NER capabilities\n",
    "nlp = spacy.load(\"en_core_web_lg\")  # or \"en_core_web_lg\"\n",
    "\n",
    "# Load the Hugging Face tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bnsapa/cybersecurity-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"bnsapa/cybersecurity-ner\")\n",
    "\n",
    "# Define a custom component to use Hugging Face model for NER\n",
    "@Language.component(\"cybersecurity_ner\")\n",
    "def cybersecurity_ner(doc):\n",
    "    tokens = [token.text for token in doc]\n",
    "    inputs = tokenizer(tokens, return_tensors=\"pt\", is_split_into_words=True, truncation=True, padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "\n",
    "    predicted_token_class_indices = torch.argmax(outputs, dim=2).squeeze().tolist()\n",
    "    predicted_labels = [model.config.id2label[idx] for idx in predicted_token_class_indices]\n",
    "\n",
    "    # Assign labels only to the first token of each entity\n",
    "    previous_word_id = None\n",
    "    for i, token in enumerate(doc):\n",
    "        word_id = inputs.word_ids()[i]\n",
    "        if word_id != previous_word_id:\n",
    "            if predicted_labels[i] != 'O':  # Only assign non-'O' labels\n",
    "                # Custom logic to improve accuracy\n",
    "                if predicted_labels[i] in [\"B-Malware\", \"B-Process\"]:\n",
    "                    token.ent_type_ = predicted_labels[i]\n",
    "                # Prevent incorrect labels for known terms\n",
    "                elif token.text.lower() in [\"applicationimpersonation\", \"set-casmailbox\"]:\n",
    "                    token.ent_type_ = \"B-Process\"\n",
    "                else:\n",
    "                    token.ent_type_ = predicted_labels[i]\n",
    "        previous_word_id = word_id\n",
    "\n",
    "    return doc\n",
    "\n",
    "# Add the custom NER component to the spaCy pipeline\n",
    "nlp.add_pipe(\"cybersecurity_ner\", last=True)\n",
    "\n",
    "# Sample text for cybersecurity NER\n",
    "text = \"\"\"\n",
    "Aoqin Dragon has used a dropper that employs a worm infection strategy using a removable device to breach a secure network environment.[1]\n",
    "\"\"\"\n",
    "# Process the text using the spaCy pipeline\n",
    "doc = nlp(text)\n",
    "\n",
    "# Display recognized entities from spaCy and the custom component\n",
    "print(\"spaCy Recognized Entities:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"Token: {ent.text}, Label: {ent.label_}\")\n",
    "\n",
    "print(\"\\nCustom Model Recognized Entities:\")\n",
    "output_found = False\n",
    "for token in doc:\n",
    "    if token.ent_type_ and token.ent_type_ != \"O\":  # Only show non-\"O\" labels\n",
    "        print(f\"Token: {token.text}, Label: {token.ent_type_}\")\n",
    "        output_found = True\n",
    "\n",
    "if not output_found:\n",
    "    print(\"No entities found by the custom model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WALEED TRADERS\\Desktop\\FYP\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\WALEED TRADERS\\Desktop\\FYP\\myenv\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\WALEED TRADERS\\Desktop\\FYP\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\WALEED TRADERS\\Desktop\\FYP\\myenv\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\WALEED TRADERS\\Desktop\\FYP\\myenv\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: UAC, Label: B-System\n",
      "Token: HKLM\\, Label: Registry Keys\n",
      "Token: SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\CredUI\\EnumerateAdministrators, Label: Registry Keys\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "\n",
    "# Load the Hugging Face tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bnsapa/cybersecurity-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"bnsapa/cybersecurity-ner\")\n",
    "\n",
    "# Initialize a blank spaCy pipeline\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Define a custom component to use the Hugging Face model for NER\n",
    "@Language.component(\"cybersecurity_ner\")\n",
    "def cybersecurity_ner(doc):\n",
    "    # Tokenize the doc using the Hugging Face tokenizer\n",
    "    tokens = [token.text for token in doc]\n",
    "\n",
    "    # Handle potential issues with tokenization\n",
    "    try:\n",
    "        inputs = tokenizer(tokens, return_tensors=\"pt\", is_split_into_words=True, truncation=True, padding=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Tokenization error: {e}\")\n",
    "        return doc\n",
    "\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "\n",
    "    # Extract token predictions and map them to their labels\n",
    "    predicted_token_class_indices = torch.argmax(outputs, dim=2).squeeze().tolist()\n",
    "    predicted_labels = [model.config.id2label[idx] for idx in predicted_token_class_indices]\n",
    "\n",
    "    # Initialize variables for subword processing\n",
    "    subword_mask = inputs.word_ids()\n",
    "    previous_word_id = None\n",
    "    full_word = \"\"\n",
    "    full_word_label = \"\"\n",
    "\n",
    "    for i, token in enumerate(doc):\n",
    "        word_id = subword_mask[i]\n",
    "\n",
    "        if word_id != previous_word_id:\n",
    "            # Finalize the previous word if needed\n",
    "            if previous_word_id is not None and full_word_label:\n",
    "                doc[previous_word_id].ent_type_ = full_word_label\n",
    "            \n",
    "            # Reset for new word\n",
    "            full_word = token.text\n",
    "            full_word_label = predicted_labels[i] if predicted_labels[i] != 'O' else ''\n",
    "        else:\n",
    "            # Accumulate the subword tokens\n",
    "            full_word += token.text.replace(\"##\", \"\")\n",
    "        \n",
    "        previous_word_id = word_id\n",
    "\n",
    "    # Assign the last processed word\n",
    "    if previous_word_id is not None and full_word_label:\n",
    "        doc[previous_word_id].ent_type_ = full_word_label\n",
    "\n",
    "    # Add additional label handling\n",
    "    for token in doc:\n",
    "        if token.text.lower().startswith(\"alert\") or token.text.lower().startswith(\"report\"):\n",
    "            token.ent_type_ = \"Alerting or Reporting\"\n",
    "        elif \"registry key\" in token.text.lower():\n",
    "            token.ent_type_ = \"Registry Keys\"\n",
    "        elif token.text.startswith(\"HKLM\\\\\") or \"SOFTWARE\" in token.text.upper() or \"Microsoft\" in token.text:\n",
    "            token.ent_type_ = \"Registry Keys\"\n",
    "        elif token.text.startswith(\"\\\\\"):\n",
    "            token.ent_type_ = \"Paths\"\n",
    "\n",
    "    return doc\n",
    "\n",
    "# Add the custom NER component to the spaCy pipeline\n",
    "nlp.add_pipe(\"cybersecurity_ner\", last=True)\n",
    "\n",
    "# Sample text to test\n",
    "text = ('''Prevent administrator accounts from being enumerated when an application is elevating through UAC since it can lead to the disclosure of account names. The Registry key is located HKLM\\\\ SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Policies\\\\CredUI\\\\EnumerateAdministrators. It can be disabled through GPO: Computer Configuration > [Policies] > Administrative Templates > Windows Components > Credential User Interface: E numerate administrator accounts on elevation. [8]''')\n",
    "\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Display the recognized entities\n",
    "output_found = False\n",
    "for token in doc:\n",
    "    if token.ent_type_ and token.ent_type_ != \"O\":  # Only show non-\"O\" labels\n",
    "        print(f\"Token: {token.text}, Label: {token.ent_type_}\")\n",
    "        output_found = True\n",
    "\n",
    "if not output_found:\n",
    "    print(\"No entitiesÂ found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
